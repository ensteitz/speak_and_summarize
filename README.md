# speak_and_summarize
Comparative study of prompt engineering strategies (zero-shot, role-based, and chain-of-thought) applied to Whisper-transcribed TED Talks. Summaries are generated using GPT-3.5-turbo and T5-small, evaluated with ROUGE and BERTScore. Built for LING-L 715 (Spring 2025).

# 🗣️ Speak & Summarize
**A Comparative Study of Prompt Engineering for Whisper-Transcribed Lectures**  
_By Rin Steitz | LING-L 715 Final Project | Spring 2025_

---

## 📌 Project Overview

This project investigates how prompt engineering impacts the quality of summaries generated by large language models (LLMs) from spoken content. I compare three prompting strategies—**zero-shot**, **role-based**, and **chain-of-thought**—on TED Talk transcripts generated using OpenAI's **Whisper-large-v3**.

Two summarization models were used:
- **GPT-3.5-turbo** (via OpenAI API)
- **T5-small** (via Hugging Face Transformers)

Summaries are automatically evaluated using **ROUGE-1/2/L** and **BERTScore (Precision, Recall, F₁)**.

---

## 🧪 Key Findings

- Role-based prompting produced the **best performance** for GPT-3.5-turbo (ROUGE-1 = 0.383, BERTScore F₁ = 0.209).
- T5-small performed best under chain-of-thought prompts (ROUGE-1 = 0.248, BERTScore F₁ = 0.074).
- Most common errors were **omissions** (especially numerical detail), followed by occasional **hallucinations** in smaller models.

---

## 🗃️ Project Structure

```bash
├── audio_files/               # Original TED Talk MP3s
├── transcripts/               # Whisper-transcribed and cleaned transcripts
├── reference_summaries/       # Manually written reference summaries
├── prompts/                   # Prompt templates used for each experiment
├── summaries_openai/          # GPT-3.5-turbo generated summaries
├── summaries_t5_local/        # T5-small generated summaries
├── evaluation/
│   ├── evaluate_all_rouge.py
│   ├── evaluate_bertscore.py
│   ├── rouge_results.csv
│   ├── bertscore_results.csv
│   └── metric_correlation.png
├── visuals/                   # Figures from the paper (bar plots, tables, etc.)
├── transcribe.py              # Whisper transcription script
├── gpt3.5_turbo_summarize.py  # GPT-3.5 summarization pipeline
├── t5_local_summarize.py      # T5-small summarization pipeline
└── LING715_final_report.pdf   # Final written report (LaTeX compiled PDF)
